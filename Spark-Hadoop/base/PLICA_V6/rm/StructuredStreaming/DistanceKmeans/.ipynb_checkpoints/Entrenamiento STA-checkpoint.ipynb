{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Procesamiento de datos\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, CountVectorizer, MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Modelos de clustering \n",
    "\n",
    "from pyspark.ml.clustering import KMeans \n",
    "\n",
    "# Pyspark\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esquema\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('version', StringType(), True),\n",
    "    StructField('time', StringType(), True),\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('type', StringType(), True),\n",
    "    StructField('event', StringType(), True),\n",
    "    StructField('data', ArrayType(StructType([\n",
    "        StructField('time',  StringType(), True),\n",
    "        StructField('imei', StringType(), True),\n",
    "        StructField('imsi', StringType(), True),\n",
    "        StructField('rat', StringType(), True),\n",
    "        ]), True))\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- version: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- time: string (nullable = true)\n",
      " |    |    |-- imei: string (nullable = true)\n",
      " |    |    |-- imsi: string (nullable = true)\n",
      " |    |    |-- rat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.schema(schema).load(\"../../datasets/rm_dataset_v1/dataset_rm_v1.json\",\n",
    "                     format=\"json\", sep=\":\", inferSchema=\"true\", header=\"true\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+----+-----+--------------------+\n",
      "|version|      time|                  id|type|event|                data|\n",
      "+-------+----------+--------------------+----+-----+--------------------+\n",
      "|    1.0|1596800148|de539085-315f-466...|  RM| DATA|[[1596800108, 359...|\n",
      "|    1.0|1596797290|de539085-315f-466...|  RM| DATA|[[1596796932, 359...|\n",
      "|    1.0|1596294961|de539085-315f-466...|  RM| DATA|[[1596294959, 359...|\n",
      "|    1.0|1596296581|de539085-315f-466...|  RM| DATA|[[1596296538, 352...|\n",
      "|    1.0|1596297481|de539085-315f-466...|  RM| DATA|[[1596297428, 358...|\n",
      "|    1.0|1596297781|de539085-315f-466...|  RM| DATA|[[1596297758, 359...|\n",
      "|    1.0|1596298021|de539085-315f-466...|  RM| DATA|[[1596297972, 356...|\n",
      "|    1.0|1596044533|de539085-315f-466...|  RM| DATA|[[1596039825, 355...|\n",
      "|    1.0|1596295981|de539085-315f-466...|  RM| DATA|[[1596294995, 353...|\n",
      "|    1.0|1596296521|de539085-315f-466...|  RM| DATA|[[1596296508, 013...|\n",
      "+-------+----------+--------------------+----+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas no útiles\n",
    "\n",
    "df = df.drop(\"event\",\"id\",\"type\",\"version\",\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expandimos los valores de la columna data en nuevas columnas del df.\n",
    "\n",
    "df = df.withColumn(\"data\", F.explode(\"data\")).select(\n",
    "  \"*\", F.col(\"data\")[\"imei\"].alias(\"imei\"), F.col(\"data\")[\"imsi\"].alias(\"imsi\"), F.col(\"data\")[\"rat\"].alias(\"rat\"), \n",
    "  F.col(\"data\")[\"time\"].alias(\"time\")\n",
    ")\n",
    "# Eliminamos la columna data tras haberla expandido.\n",
    "\n",
    "df = df.drop(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio de formato de time\n",
    "\n",
    "def timeFormat(time_string):\n",
    "    datetime_string = datetime.utcfromtimestamp(int(time_string)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return datetime_string\n",
    "\n",
    "timeFormatUDF = F.udf(lambda ts: timeFormat(ts)) \n",
    "\n",
    "df = df.withColumn(\"time\", timeFormatUDF(F.col(\"time\")).cast(TimestampType()))\n",
    "df = df.withColumn(\"time\", F.date_format(F.col(\"time\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos año, mes, dia, hora, minuto y segundo de time\n",
    "\n",
    "df = df.withColumn(\"year\", F.year(F.col(\"time\")))\n",
    "df = df.withColumn(\"month\", F.month(F.col(\"time\")))\n",
    "df = df.withColumn(\"day\", F.dayofmonth(F.col(\"time\")))\n",
    "df = df.withColumn(\"hour\", F.hour(F.col(\"time\")))\n",
    "df = df.withColumn(\"minute\", F.minute(F.col(\"time\")))\n",
    "df = df.withColumn(\"second\", F.second(F.col(\"time\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos MCC, MNC y MSIN de la columna IMSI\n",
    "\n",
    "df = df.withColumn('mcc', df.imsi.substr(1,3))\n",
    "df = df.withColumn('mnc', df.imsi.substr(4,2))\n",
    "df = df.withColumn('msin', df.imsi.substr(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Formato de los IMEI: TAC -- Serial_Number -- CD (15 digitos) \"\"\"\n",
    "# Separamos TAC, SNR y CD de la columna IMEI\n",
    "\n",
    "df = df.withColumn('tac', df.imei.substr(1,8))\n",
    "df = df.withColumn('snr', df.imei.substr(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos la columna YEAR con MinMaxScaler \n",
    "\n",
    "df = df.withColumn(\"year\", df[\"year\"].cast(FloatType()))\n",
    "max_year = 3000\n",
    "min_year = 0\n",
    "df = df.withColumn(\"year\", (F.col(\"year\") - min_year) / (max_year - min_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos columnas month, day, hour, minute y second\n",
    "\n",
    "df = df.withColumn(\"month\", (F.col(\"month\") - 1) / (12 - 1))\n",
    "df = df.withColumn(\"day\", (F.col(\"day\") - 1) / (31 - 1))\n",
    "df = df.withColumn(\"hour\", (F.col(\"hour\") - 0) / (23 - 0))\n",
    "df = df.withColumn(\"minute\", (F.col(\"minute\") - 0) / (59 - 0))\n",
    "df = df.withColumn(\"second\", (F.col(\"second\") - 0) / (59 - 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos indexado de las columnas categoricas\n",
    "\n",
    "stringIndexerRat = StringIndexer(inputCol=\"rat\", outputCol=\"rat_index\",handleInvalid=\"keep\")\n",
    "stringIndexerMcc = StringIndexer(inputCol=\"mcc\", outputCol=\"mcc_index\",handleInvalid=\"keep\")\n",
    "stringIndexerMnc = StringIndexer(inputCol=\"mnc\", outputCol=\"mnc_index\",handleInvalid=\"keep\")\n",
    "stringIndexerMsin = StringIndexer(inputCol=\"msin\", outputCol=\"msin_index\",handleInvalid=\"keep\")\n",
    "stringIndexerTac = StringIndexer(inputCol=\"tac\", outputCol=\"tac_index\",handleInvalid=\"keep\")\n",
    "stringIndexerSnr = StringIndexer(inputCol=\"snr\", outputCol=\"snr_index\",handleInvalid=\"keep\")\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexerRat,stringIndexerMcc,stringIndexerMnc,\n",
    "                            stringIndexerMsin,stringIndexerTac,stringIndexerSnr])\n",
    "\n",
    "\n",
    "String_Indexer_Model = pipeline.fit(df)\n",
    "df = String_Indexer_Model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de vector de características\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=['year','month','day','hour','minute','second',\n",
    "                                        'rat_index','mcc_index','mnc_index','msin_index',\n",
    "                                        'tac_index','snr_index'], outputCol = \"features\")\n",
    "\n",
    "df = vector_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistanceKmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrucutra del dataset normal\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('label', StringType(), True), # no\n",
    "    StructField('features', ArrayType(DoubleType()), True), # si\n",
    "    ])  \n",
    "\n",
    "df_train = spark.read.schema(schema).option(\"mode\", \"DROPMALFORMED\").json(\n",
    "    '../../deteccion_anomalias/preprocesamiento/KMeansStringIndexer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrucutra del dataset normal\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('rf_id', StringType(), True), # no\n",
    "    StructField('time', TimestampType(), True), # si\n",
    "    StructField('rat', StringType(), True), # si\n",
    "    StructField('imei', StringType(), True), # si\n",
    "    StructField('imsi', StringType(), True), # si\n",
    "    StructField('label', StringType(), True), # no\n",
    "    StructField('year', DoubleType(), True), # si\n",
    "    StructField('month', DoubleType(), True), # si\n",
    "    StructField('day', DoubleType(), True), # si\n",
    "    StructField('hour', DoubleType(), True), # si\n",
    "    StructField('minute', DoubleType(), True), # si\n",
    "    StructField('second', DoubleType(), True), # si\n",
    "    StructField('mcc', StringType(), True), # si\n",
    "    StructField('mnc', StringType(), True), # si\n",
    "    StructField('msin', StringType(), True), # si\n",
    "    StructField('tac_a', StringType(), True), # no\n",
    "    StructField('tac_b', StringType(), True), # no\n",
    "    StructField('snr', StringType(), True), # no\n",
    "    StructField('cd', StringType(), True), # si\n",
    "    StructField('rat_ohe', ArrayType(DoubleType()), True), # si\n",
    "    StructField('cat_imsi', ArrayType(StringType()), True), # si\n",
    "    StructField('cat_imei', ArrayType(StringType()), True), # si\n",
    "    StructField('imei_vec', ArrayType(DoubleType()), True), # si\n",
    "    StructField('imsi_vec', ArrayType(DoubleType()), True), # si\n",
    "    StructField('features', ArrayType(DoubleType())), # si\n",
    "    ])  \n",
    "\n",
    "df_train = spark.read.schema(schema).option(\"mode\", \"DROPMALFORMED\").json(\n",
    "    '../../deteccion_anomalias/preprocesamiento/KMeansWord2Vec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de calculo de pertenencia a un cluster\n",
    "\n",
    "def centroid (k,centers):\n",
    "    return centers[k].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de calculo de distancia euclidea al centroid\n",
    "\n",
    "def distToCentroid(datapt, centroid):\n",
    "    return math.sqrt(Vectors.squared_distance(datapt, centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = ArrayType(DoubleType(), containsNull=False)\n",
    "udf_foo = F.udf(lambda x:x, new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos df en datos normales\n",
    "\n",
    "df_normal = df_train.filter(df_train.label == 'Normal')\n",
    "df_normal = df_normal.withColumn(\"features\",udf_foo(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamiento y predicción\n",
    "\n",
    "kmeans = KMeans(k=30, maxIter=100, tol=1e-4, seed=319869)\n",
    "model = kmeans.fit(df_normal.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = \"{}/data/distanceKmeansRmSIModel.bin\".format(base_path)\n",
    "# model_output_path = \"{}/data/distanceKmeansRmW2VModel.bin\".format(base_path)\n",
    "model.write().overwrite().save(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = model.transform(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorCent = F.udf(lambda k: centroid(k,centers), ArrayType(DoubleType()))\n",
    "euclDistance = F.udf(lambda data,centroid: distToCentroid(data,centroid),FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos valor del centroid más cercano.\n",
    "\n",
    "df_normal = df_normal.withColumn('centroid', vectorCent(F.col('prediction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos distancia al centroid más cercano.\n",
    "\n",
    "df_normal = df_normal.withColumn('distance', euclDistance(F.col('features'),F.col('centroid')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = df_normal.groupBy('prediction').agg(F.sort_array(F.collect_list('distance'), asc=False).alias('distances'))\\\n",
    ".orderBy('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = threshold.select('distances').toPandas()['distances'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_path = '{}/data/thresholdStringIndexer.npy'.format(base_path)\n",
    "# threshold_path = '{}/data/thresholdWord2Vec.npy'.format(base_path)\n",
    "np.save(threshold_path, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
